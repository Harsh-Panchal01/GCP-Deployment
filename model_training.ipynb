{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Exploratory analysis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# model training\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import auc, precision_recall_curve, accuracy_score, roc_auc_score, precision_score, recall_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# data peprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# for saving model\n",
    "import joblib\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('churn.csv') # import data\n",
    "df.head() # showing first 5 rows of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature and Target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['RowNumber', 'CustomerId', 'Surname','Exited'], axis=1) # creating feature space\n",
    "y = df['Exited'] # target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting int into ordinal category\n",
    "\n",
    "X['Tenure'] = X['Tenure'].astype(str) \n",
    "X['NumOfProducts'] = X['NumOfProducts'].astype(str) \n",
    "X['HasCrCard'] = X['HasCrCard'].astype(str)\n",
    "X['IsActiveMember'] = X['IsActiveMember'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Column Transformers\n",
    "numerical_features = X.select_dtypes(exclude=\"object\").columns\n",
    "categorical_features = X.select_dtypes(include=\"object\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['CreditScore', 'Age', 'Balance', 'EstimatedSalary'], dtype='object'),\n",
       " Index(['Geography', 'Gender', 'Tenure', 'NumOfProducts', 'HasCrCard',\n",
       "        'IsActiveMember'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features, categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_df = pd.get_dummies(df[categorical_features], prefix_sep=\"__\",\n",
    "#                                   columns=categorical_features)  \n",
    "# categorical_df = categorical_df.astype(int)                          \n",
    "# corr_df = pd.concat([df[numerical_features],categorical_df, df['Exited'] ] , axis=1) \n",
    "\n",
    "# corr_mat = corr_df.corr()\n",
    "# corr_target = abs(corr_mat[\"Exited\"])\n",
    "\n",
    "# # Finding relevant features by filtering our correlation matrix with the features which has greater than 0.2 correlation with target data\n",
    "# relevant_features = corr_target[corr_target>0.2]\n",
    "# relevant_features =pd.DataFrame(relevant_features)\n",
    "# # plotting the heat map of relevant features\n",
    "\n",
    "# plt.figure(figsize=(25,20))\n",
    "# sns.heatmap(corr_mat, annot=True, cmap=plt.cm.Reds)\n",
    "# plt.title(' Correlation of relevant features ' , size = 15)\n",
    "# plt.xlabel('Target data',  size = 15)\n",
    "# plt.ylabel('Features',  size = 15)\n",
    "# plt.xticks(size=15)\n",
    "# plt.yticks(size=15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y,\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance',\n",
       "       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' standard scaling numeric features and one hot encoding categorical features'''\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder()\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", oh_transformer, categorical_features),\n",
    "         (\"StandardScaler\", numeric_transformer, numerical_features),        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming train and test data\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Preprocessor for future data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(preprocessor, \"preprocessor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 28), (2000, 28))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape, X_test_scaled.shape # checking shape of train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    7963\n",
       "1    2037\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts() # checking counts of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we observe, our data is imbalanced, with class 0 counts being almost four times those of class 1. To address this issue, we can employ balancing techniques such as oversampling, undersampling, or a combination of both.\n",
    "\n",
    "However, using undersampling alone has a significant drawback, as it leads to information loss. Hence, I typically avoid relying solely on undersampling.\n",
    "\n",
    "To balance the data, we can utilize Synthetic Minority Oversampling Technique (SMOTE) for oversampling class 1. Additionally, altering class weights during model implementation is another approach.\n",
    "\n",
    "### However, for this study, we won't be implementing any sampling methods as our primary goal is model deployment on GCP. Instead, we'll focus on proper model evaluation metrics.\n",
    "### Given the data's nature, it's crucial to emphasize class 1, which corresponds to customer churning. Thus, optimizing the model's Recall, aimed at reducing false negatives, is our priority.\n",
    "### Considering the data imbalance, the Precision-Recall curve is also more suitable evaluation tool for different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Model Performance for Training set:\n",
      "Recall: 0.38\n",
      "Precision Recall Curve AUC: 0.61\n",
      "--------------------\n",
      "Model Performance for Testing set:\n",
      "Recall: 0.36\n",
      "Precision Recall Curve AUC: 0.59\n",
      "####################\n",
      "\n",
      "\n",
      "Support Vector Classifier\n",
      "Model Performance for Training set:\n",
      "Recall: 0.43\n",
      "Precision Recall Curve AUC: 0.70\n",
      "--------------------\n",
      "Model Performance for Testing set:\n",
      "Recall: 0.41\n",
      "Precision Recall Curve AUC: 0.68\n",
      "####################\n",
      "\n",
      "\n",
      "Random Forest Classifier\n",
      "Model Performance for Training set:\n",
      "Recall: 1.00\n",
      "Precision Recall Curve AUC: 1.00\n",
      "--------------------\n",
      "Model Performance for Testing set:\n",
      "Recall: 0.45\n",
      "Precision Recall Curve AUC: 0.65\n",
      "####################\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model Performance for Training set:\n",
      "Recall: 0.83\n",
      "Precision Recall Curve AUC: 0.92\n",
      "--------------------\n",
      "Model Performance for Testing set:\n",
      "Recall: 0.50\n",
      "Precision Recall Curve AUC: 0.65\n",
      "####################\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model Performance for Training set:\n",
      "Recall: 0.64\n",
      "Precision Recall Curve AUC: 0.81\n",
      "--------------------\n",
      "Model Performance for Testing set:\n",
      "Recall: 0.50\n",
      "Precision Recall Curve AUC: 0.69\n",
      "####################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model implementation\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(), \n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(), \n",
    "    \"CatBoosting Classifier\": CatBoostClassifier(verbose=False)\n",
    "}\n",
    "model_list = [] # creating empty list to add model name\n",
    "recall = [] # creating empty list to store test recall\n",
    "precision_recall_curve_auc = [] # creating empty list to store test auc\n",
    "\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train_scaled, y_train) # model fitting\n",
    "\n",
    "\n",
    "    # predictions\n",
    "    y_train_pred = model.predict(X_train_scaled) # train prediction\n",
    "    y_test_pred = model.predict(X_test_scaled) # test prediction\n",
    "\n",
    "    # Evaluate Models\n",
    "\n",
    "    pr_train, re_train, th_train = precision_recall_curve(y_train, y_train_pred) \n",
    "    pr_test, re_test, th_test = precision_recall_curve(y_test, y_test_pred)\n",
    "    recall_train = recall_score(y_train, y_train_pred)\n",
    "    recall_test = recall_score(y_test, y_test_pred)\n",
    "    auc_train = auc(re_train, pr_train)\n",
    "    auc_test = auc(re_test, pr_test)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print(\"Model Performance for Training set:\")\n",
    "    print('Recall: {:.2f}'.format(recall_train))\n",
    "    print('Precision Recall Curve AUC: {:.2f}'.format(auc_train))\n",
    "\n",
    "    print(\"-\"*20)\n",
    "\n",
    "    print(\"Model Performance for Testing set:\")\n",
    "    print('Recall: {:.2f}'.format(recall_test))\n",
    "    print('Precision Recall Curve AUC: {:.2f}'.format(auc_test))\n",
    "    recall.append(recall_test)\n",
    "    precision_recall_curve_auc.append(auc_test)\n",
    "    print(\"#\"*20)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrame of models' results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>0.496314</td>\n",
       "      <td>0.690880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.496314</td>\n",
       "      <td>0.652554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.447174</td>\n",
       "      <td>0.651266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.679869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.358722</td>\n",
       "      <td>0.593893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Name    Recall       AUC\n",
       "4     CatBoosting Classifier  0.496314  0.690880\n",
       "3              XGBClassifier  0.496314  0.652554\n",
       "2   Random Forest Classifier  0.447174  0.651266\n",
       "1  Support Vector Classifier  0.405405  0.679869\n",
       "0        Logistic Regression  0.358722  0.593893"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(model_list, recall, precision_recall_curve_auc)), columns=['Model Name', 'Recall', 'AUC']).sort_values(by=[\"Recall\", \"AUC\"],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As Catboost Classifier has the highets recall and AUC. We will implement Catboost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.496\n"
     ]
    }
   ],
   "source": [
    "# model implementation\n",
    "cat_model = CatBoostClassifier(verbose= False)\n",
    "cat_model.fit(X_train_scaled, y_train) # model fit\n",
    "y_pred_test = cat_model.predict(X_test_scaled) # prediction in test data\n",
    "\n",
    "recall_test = recall_score(y_test, y_pred_test) # recall score\n",
    "print(\"Recall:\", round(recall_test,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since our primary goal is to deploy the application on GCP, I'm currently not focusing on tuning the model's hyperparameters. We can do it later using gridserchcv and using cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Catboost Classifier Trained model in pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('customer_churn_catboost_model.pkl', 'wb') as pickle_file:\n",
    "#     pickle.dump(cat_model, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
